{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb462f2c-6601-4bc3-a3ad-f81ace976ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Set global seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Configure plotting style\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14,\n",
    "    'font.family': 'Arial',\n",
    "    'axes.linewidth': 1.5,\n",
    "    'axes.labelsize': 14,\n",
    "    'axes.titlesize': 15,\n",
    "    'xtick.labelsize': 13,\n",
    "    'ytick.labelsize': 13,\n",
    "    'legend.fontsize': 12,\n",
    "    'figure.dpi': 600,\n",
    "    'savefig.dpi': 600,\n",
    "    'savefig.bbox': 'tight',\n",
    "    'savefig.pad_inches': 0.2,\n",
    "})\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "# 1. Load EEM data (replace NaN with 0)\n",
    "def load_eem(filepath):\n",
    "    try:\n",
    "        df = pd.read_csv(filepath, index_col=0)\n",
    "        eem = df.values.astype(np.float32)\n",
    "        eem = np.nan_to_num(eem, nan=0.0)\n",
    "        return eem\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "# 2. Construct dataset from metadata and EEM files\n",
    "def load_dataset(metadata_path, data_dir):\n",
    "    meta = pd.read_csv(metadata_path, sep=\";\")\n",
    "    X, y = [], []\n",
    "    for _, row in meta.iterrows():\n",
    "        sid = row[\"sample_identifier\"]\n",
    "        csv_path = os.path.join(data_dir, f\"{sid}.csv\")\n",
    "        eem = load_eem(csv_path)\n",
    "        if eem is None:\n",
    "            continue\n",
    "        X.append(eem)\n",
    "        y.append([row[\"conc_cip\"], row[\"conc_nap\"], row[\"conc_zol\"]])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Load natural water and wastewater datasets\n",
    "X_nat, y_nat = load_dataset(\"Natural_water/metadata_natural_water.csv\", \"Natural_water\")\n",
    "X_wast, y_wast = load_dataset(\"Wastewater/metadata_wastewater.csv\", \"Wastewater\")\n",
    "\n",
    "# Create source labels: 0 = natural water (NW), 1 = wastewater (WW)\n",
    "labels_nat = np.zeros(len(X_nat), dtype=int)\n",
    "labels_wast = np.ones(len(X_wast), dtype=int)\n",
    "\n",
    "# Merge datasets\n",
    "X_raw = np.concatenate([X_nat, X_wast], axis=0)\n",
    "y_raw = np.concatenate([y_nat, y_wast], axis=0)\n",
    "source_labels = np.concatenate([labels_nat, labels_wast], axis=0)\n",
    "\n",
    "n_samples, n_targets = X_raw.shape[0], y_raw.shape[1]\n",
    "\n",
    "# ================================================================================\n",
    "# Generate sample type labels (0=single OMPs, 1=mixture, 2=blank)\n",
    "# ================================================================================\n",
    "sample_type = np.zeros(n_samples, dtype=int)  # default to single\n",
    "for i in range(n_samples):\n",
    "    concs = y_raw[i]\n",
    "    if np.all(concs == 0):\n",
    "        sample_type[i] = 2  # blank (all zeros)\n",
    "    elif np.sum(concs > 0) == 1:\n",
    "        sample_type[i] = 0  # single OMPs (exactly one >0)\n",
    "    else:\n",
    "        sample_type[i] = 1  # mixture (two or three >0)\n",
    "\n",
    "n_single = np.sum(sample_type == 0)\n",
    "n_mixture = np.sum(sample_type == 1)\n",
    "n_blank = np.sum(sample_type == 2)\n",
    "\n",
    "\n",
    "# 3. Define CNN architecture for EEM spectral analysis\n",
    "class EEMCNN(nn.Module):\n",
    "    def __init__(self, num_targets=3):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.GELU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.GELU(),\n",
    "            nn.AdaptiveAvgPool2d((8, 8)),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 8 * 8, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128, num_targets)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# 4. Compute within-relative-error rates at concentration thresholds\n",
    "def compute_within_error_rates(y_true, y_pred, thresholds_conc=[2, 5, 10], error_levels=[0.1, 0.15, 0.2]):\n",
    "    results = {}\n",
    "    targets = [\"CIP\", \"NAP\", \"ZOL\"]\n",
    "    for i, name in enumerate(targets):\n",
    "        results[name] = {}\n",
    "        y_t = y_true[:, i]\n",
    "        y_p = y_pred[:, i]\n",
    "        for th in thresholds_conc:\n",
    "            mask = y_t > th\n",
    "            n_valid = np.sum(mask)\n",
    "            if n_valid == 0:\n",
    "                for err in error_levels:\n",
    "                    results[name][f\"> {th} μg/L @ ±{int(err*100)}%\"] = 0.0\n",
    "                continue\n",
    "            rel_err = np.abs((y_t[mask] - y_p[mask]) / y_t[mask])\n",
    "            for err in error_levels:\n",
    "                within = np.sum(rel_err <= err)\n",
    "                rate = within / n_valid\n",
    "                results[name][f\"> {th} μg/L @ ±{int(err*100)}%\"] = rate\n",
    "    return results\n",
    "\n",
    "# 5. Calculate limits of detection (LOD) using blank samples\n",
    "def calculate_lod(y_true, y_pred, compound_name):\n",
    "    n_blank = len(y_true)\n",
    "\n",
    "    if n_blank < 7: \n",
    "        return np.nan, np.nan, n_blank\n",
    "\n",
    "    sigma_blank = np.std(y_pred, ddof=1) \n",
    "        \n",
    "       \n",
    "    S = 1.0\n",
    "    LOD = (3.3 * sigma_blank) / S\n",
    "    LOQ = (10 * sigma_blank) / S\n",
    "    \n",
    "    return LOD, LOQ, n_blank\n",
    "\n",
    "# 6. Perform repeated stratified k-fold cross-validation\n",
    "n_splits = 5\n",
    "n_repeats = 5\n",
    "rkf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "n_folds = n_splits * n_repeats\n",
    "oof_predictions_raw = np.full((n_folds, n_samples, n_targets), np.nan)\n",
    "fold_r2_scores = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(rkf.split(X_raw, source_labels)):\n",
    "    X_train, X_test = X_raw[train_idx], X_raw[test_idx]\n",
    "    y_train, y_test = y_raw[train_idx], y_raw[test_idx]\n",
    "\n",
    "\n",
    "    X_min, X_max = X_train.min(), X_train.max()\n",
    "    X_train_norm = (X_train - X_min) / (X_max - X_min + 1e-8)\n",
    "    X_test_norm = (X_test - X_min) / (X_max - X_min + 1e-8)\n",
    "\n",
    "\n",
    "    scaler_y = StandardScaler()\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "    y_test_scaled = scaler_y.transform(y_test)\n",
    "\n",
    "\n",
    "    X_train_t = torch.tensor(X_train_norm[:, None, :, :], dtype=torch.float32)\n",
    "    X_test_t = torch.tensor(X_test_norm[:, None, :, :], dtype=torch.float32)\n",
    "    y_train_t = torch.tensor(y_train_scaled, dtype=torch.float32)\n",
    "    y_test_t = torch.tensor(y_test_scaled, dtype=torch.float32)\n",
    "    train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=8, shuffle=True)\n",
    "\n",
    "\n",
    "    model = EEMCNN(num_targets=n_targets).to(device)\n",
    "    X_test_t = X_test_t.to(device)\n",
    "    y_test_t = y_test_t.to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=120)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(120):\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "  \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_scaled = model(X_test_t).cpu().numpy()\n",
    "        y_pred_orig = scaler_y.inverse_transform(y_pred_scaled)\n",
    "        y_pred_orig = np.maximum(y_pred_orig, 0)\n",
    "    \n",
    "    r2_fold = [r2_score(y_test[:, i], y_pred_orig[:, i]) for i in range(n_targets)]\n",
    "    fold_r2_scores.append(r2_fold)\n",
    "    oof_predictions_raw[fold, test_idx, :] = y_pred_orig\n",
    "\n",
    "oof_predictions = np.full((n_samples, n_targets), np.nan)\n",
    "for i in range(n_samples):\n",
    "    preds = oof_predictions_raw[:, i, :]\n",
    "    valid = ~np.isnan(preds[:, 0])\n",
    "    oof_predictions[i] = np.mean(preds[valid], axis=0)\n",
    "oof_predictions = np.maximum(oof_predictions, 0)\n",
    "\n",
    "overall_r2 = [r2_score(y_raw[:, i], oof_predictions[:, i]) for i in range(n_targets)]\n",
    "mean_overall_r2 = np.mean(overall_r2)\n",
    "fold_r2_scores = np.array(fold_r2_scores)\n",
    "mean_fold_r2 = np.mean(fold_r2_scores, axis=0)\n",
    "std_fold_r2 = np.std(fold_r2_scores, axis=0)\n",
    "\n",
    "non_blank_mask = (sample_type != 2)\n",
    "y_non_blank = y_raw[non_blank_mask]\n",
    "oof_non_blank = oof_predictions[non_blank_mask]\n",
    "source_non_blank = source_labels[non_blank_mask]\n",
    "sample_type_non_blank = sample_type[non_blank_mask]\n",
    "\n",
    "# 7. Generate Prediction vs. True plots with 4-way distinction (NW/WW × Single/Mixture)\n",
    "# Generate prediction vs. true plots with 6-category visual encoding\n",
    "#   ○ = natural water (NW), □ = wastewater (WW)\n",
    "#   Solid fill = single OMP, open fill = mixture (2-3 OMPs)\n",
    "#   × = zero OMPs samples (light blue: NW matrix; light orange: WW matrix)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), constrained_layout=True)\n",
    "\n",
    "for i, (name, color) in enumerate(zip(targets, colors)):\n",
    "    y_true = y_raw[:, i]\n",
    "    y_pred = oof_predictions[:, i]\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # NW zero OMPs: light blue cross (small size to reduce origin clutter)\n",
    "    mask = (source_labels == 0) & (sample_type == 2)\n",
    "    if np.any(mask):\n",
    "        ax.scatter(y_true[mask], y_pred[mask],\n",
    "                   marker='x', color='#87CEFA', s=45, alpha=0.8,\n",
    "                   linewidths=1.8)\n",
    "    \n",
    "    # WW zero OMPs: light orange cross\n",
    "    mask = (source_labels == 1) & (sample_type == 2)\n",
    "    if np.any(mask):\n",
    "        ax.scatter(y_true[mask], y_pred[mask],\n",
    "                   marker='x', color='#FFB366', s=45, alpha=0.8,\n",
    "                   linewidths=1.8)\n",
    "    \n",
    "    # NW single: solid circle with black edge\n",
    "    mask = (source_labels == 0) & (sample_type == 0)\n",
    "    if np.any(mask):\n",
    "        ax.scatter(y_true[mask], y_pred[mask],\n",
    "                   marker='o', facecolors=color, edgecolors='k',\n",
    "                   s=80, linewidths=0.8, alpha=0.8)\n",
    "    \n",
    "    # NW mixture: open circle with colored edge\n",
    "    mask = (source_labels == 0) & (sample_type == 1)\n",
    "    if np.any(mask):\n",
    "        ax.scatter(y_true[mask], y_pred[mask],\n",
    "                   marker='o', facecolors='white', edgecolors=color,\n",
    "                   s=80, linewidths=1.8, alpha=0.9)\n",
    "    \n",
    "    # WW single: solid square with black edge\n",
    "    mask = (source_labels == 1) & (sample_type == 0)\n",
    "    if np.any(mask):\n",
    "        ax.scatter(y_true[mask], y_pred[mask],\n",
    "                   marker='s', facecolors=color, edgecolors='k',\n",
    "                   s=80, linewidths=0.8, alpha=0.8)\n",
    "    \n",
    "    # WW mixture: open square with colored edge\n",
    "    mask = (source_labels == 1) & (sample_type == 1)\n",
    "    if np.any(mask):\n",
    "        ax.scatter(y_true[mask], y_pred[mask],\n",
    "                   marker='s', facecolors='white', edgecolors=color,\n",
    "                   s=80, linewidths=1.8, alpha=0.9)\n",
    "    \n",
    "    # Reference lines\n",
    "    lims = [min(y_true.min(), y_pred.min()) - 1, max(y_true.max(), y_pred.max()) + 1]\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    ax.plot(lims, lims, 'k--', linewidth=1.5)\n",
    "    x_line = np.linspace(lims[0], lims[1], 200)\n",
    "    ax.fill_between(x_line, 0.9 * x_line, 1.1 * x_line, color='lightgray', alpha=0.3)\n",
    "    ax.plot(x_line, 1.2 * x_line, 'gray', linestyle='-.', linewidth=1.0, alpha=0.6)\n",
    "    ax.plot(x_line, 0.8 * x_line, 'gray', linestyle='-.', linewidth=1.0, alpha=0.6)\n",
    "    \n",
    "    ax.set_xlabel('True Concentration (μg/L)')\n",
    "    ax.set_ylabel('Predicted Concentration (μg/L)')\n",
    "    ax.set_title(f'{name} (R² = {overall_r2[i]:.3f})')\n",
    "    ax.grid(True, linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.savefig(\"prediction_vs_true_cv.pdf\", dpi=600)\n",
    "plt.savefig(\"prediction_vs_true_cv.png\", dpi=600)\n",
    "plt.show()\n",
    "\n",
    "# 8. Print within-relative-error rates table\n",
    "print(\"Within-relative-error rates\\n\")\n",
    "error_results = compute_within_error_rates(y_raw, oof_predictions)\n",
    "col_keys = list(error_results[\"CIP\"].keys())\n",
    "print(\"-\" * 80)\n",
    "header = f\"{'Target':<8}\" + \"\".join([f\"{k:>14}\" for k in col_keys])\n",
    "print(header)\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for target in [\"CIP\", \"NAP\", \"ZOL\"]:\n",
    "    row = f\"{target:<8}\"\n",
    "    for k in col_keys:\n",
    "        rate_pct = error_results[target][k] * 100\n",
    "        row += f\"{rate_pct:>13.1f}%\"\n",
    "    print(row)\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# 9. Generate Bland-Altman plots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6), constrained_layout=True)\n",
    "print(\"Bland–Altman (mean–difference) plots\\n\")\n",
    "\n",
    "for i, (name, color) in enumerate(zip(targets, colors)):\n",
    "    y_true = y_raw[:, i]\n",
    "    y_pred = oof_predictions[:, i]\n",
    "    mean_vals = (y_true + y_pred) / 2\n",
    "    diff = y_pred - y_true\n",
    "    mean_diff = np.mean(diff)\n",
    "    std_diff = np.std(diff)\n",
    "    loa_upper = mean_diff + 1.96 * std_diff\n",
    "    loa_lower = mean_diff - 1.96 * std_diff\n",
    "    \n",
    "    ax = axes[i]\n",
    "    ax.scatter(mean_vals, diff, alpha=0.7, color=color, edgecolor='k', s=60)\n",
    "    ax.axhline(mean_diff, color='red', linestyle='-', label=f'Mean = {mean_diff:.2f}')\n",
    "    ax.axhline(loa_upper, color='gray', linestyle='--', label=f'LoA+ = {loa_upper:.2f}')\n",
    "    ax.axhline(loa_lower, color='gray', linestyle='--', label=f'LoA- = {loa_lower:.2f}')\n",
    "    ax.fill_between(np.linspace(mean_vals.min(), mean_vals.max(), 100),\n",
    "                    loa_lower, loa_upper, color='gray', alpha=0.1)\n",
    "    ax.set_xlabel('Mean of True and Predicted (μg/L)')\n",
    "    ax.set_ylabel('Difference (Pred - True, μg/L)')\n",
    "    ax.set_title(f'{name}', loc='center')  \n",
    "    ax.legend(fontsize=10, frameon=True)\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.savefig(\"bland_altman_cv.pdf\")\n",
    "plt.savefig(\"bland_altman_cv.png\")\n",
    "plt.show()\n",
    "\n",
    "# 10. Generate performance stability plot across folds\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6), constrained_layout=True)\n",
    "print(\"Model performance stability\\n\")\n",
    "\n",
    "\n",
    "parts = ax.violinplot(fold_r2_scores, showmeans=True, showmedians=True, widths=0.8)\n",
    "for pc, color in zip(parts['bodies'], colors):\n",
    "    pc.set_facecolor(color)\n",
    "    pc.set_alpha(0.7)\n",
    "parts['cmeans'].set_color('k')\n",
    "parts['cmedians'].set_color('k')\n",
    "ax.set_xticks([1, 2, 3])\n",
    "ax.set_xticklabels(targets)\n",
    "ax.set_ylabel('R² Score')\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.set_title('R² distribution across folds', loc='center') \n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.savefig(\"cross_fold_stability.pdf\")\n",
    "plt.savefig(\"cross_fold_stability.png\")\n",
    "plt.show()\n",
    "\n",
    "# 11. Generate Summary Combined Plot (6×6 inches, 600 dpi)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6), constrained_layout=True)\n",
    "print(\"Summary combined prediction plot\\n\")\n",
    "\n",
    "\n",
    "markers = ['o', 's', '^']\n",
    "for i, (name, color, marker) in enumerate(zip(targets, colors, markers)):\n",
    "    y_t = y_raw[:, i]\n",
    "    y_p = oof_predictions[:, i]\n",
    "    ax.scatter(y_t, y_p, label=name, color=color, marker=marker, s=80, alpha=0.7, edgecolors='k', linewidth=0.6)\n",
    "\n",
    "# Axis limits and reference lines\n",
    "y_all_true = np.concatenate([y_raw[:, i] for i in range(3)])\n",
    "y_all_pred = np.concatenate([oof_predictions[:, i] for i in range(3)])\n",
    "lim_min = min(y_all_true.min(), y_all_pred.min())\n",
    "lim_max = max(y_all_true.max(), y_all_pred.max())\n",
    "margin = (lim_max - lim_min) * 0.05\n",
    "safe_lims = [lim_min - margin, lim_max + margin]\n",
    "ax.set_xlim(safe_lims)\n",
    "ax.set_ylim(safe_lims)\n",
    "\n",
    "ax.plot(safe_lims, safe_lims, 'k--', linewidth=2.0, label='Ideal')\n",
    "x_line = np.linspace(safe_lims[0], safe_lims[1], 200)\n",
    "ax.fill_between(x_line, 0.9 * x_line, 1.1 * x_line, color='lightgray', alpha=0.4, label='±10%')\n",
    "\n",
    "ax.set_xlabel('Measured (μg/L)')\n",
    "ax.set_ylabel('Predicted (μg/L)')\n",
    "ax.set_title('Combined prediction performance', loc='center')  \n",
    "ax.grid(True, linestyle='--', alpha=0.4)\n",
    "ax.legend(loc='lower right', frameon=True, facecolor='white', edgecolor='black')\n",
    "\n",
    "# R² annotation\n",
    "text_str = f\"CIP: R² = {overall_r2[0]:.3f}\\nNAP: R² = {overall_r2[1]:.3f}\\nZOL: R² = {overall_r2[2]:.3f}\"\n",
    "ax.text(0.05, 0.95, text_str, transform=ax.transAxes, fontsize=11,\n",
    "        verticalalignment='top',\n",
    "        bbox=dict(boxstyle=\"round,pad=0.4\", facecolor=\"white\", edgecolor=\"black\", linewidth=1.5))\n",
    "\n",
    "plt.savefig(\"summary_prediction_combined_cv.pdf\")\n",
    "plt.savefig(\"summary_prediction_combined_cv.png\")\n",
    "plt.show()\n",
    "\n",
    "# 12. Calculate and report LOD/LOQ for full(N=106), NW, and WW datasets\n",
    "nw_indices = np.where(source_labels == 0)[0]\n",
    "ww_indices = np.where(source_labels == 1)[0]\n",
    "\n",
    "lod_results = {\n",
    "    \"Full Dataset\": {\"indices\": np.arange(n_samples), \"n_samples\": n_samples},\n",
    "    \"Natural Water (NW)\": {\"indices\": nw_indices, \"n_samples\": len(nw_indices)},\n",
    "    \"Wastewater (WW)\": {\"indices\": ww_indices, \"n_samples\": len(ww_indices)}\n",
    "}\n",
    "\n",
    "print(\"\\nLimits of detection (LOD) and quantification (LOQ) \\n\")\n",
    "print(f\"{'Dataset':<25} {'Compound':<8} {'LOD (μg/L)':>12} {'LOQ (μg/L)':>12} {'Blank n':>8}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "lod_table = []\n",
    "for dataset_name, info in lod_results.items():\n",
    "    idx = info[\"indices\"]\n",
    "    n_total = info[\"n_samples\"]\n",
    "\n",
    "    \n",
    "    for i, compound in enumerate([\"CIP\", \"NAP\", \"ZOL\"]):\n",
    "        blank_mask = (y_raw[idx, i] == 0)\n",
    "        y_t_blank = y_raw[idx, i][blank_mask]\n",
    "        y_p_blank = oof_predictions[idx, i][blank_mask]\n",
    "    \n",
    "        LOD, LOQ, n_blank = calculate_lod(y_t_blank, y_p_blank, compound)\n",
    "        \n",
    "        \n",
    "        lod_str = f\"{LOD:.2f}\" if not np.isnan(LOD) else \"N/A\"\n",
    "        loq_str = f\"{LOQ:.2f}\" if not np.isnan(LOQ) else \"N/A\"\n",
    "        print(f\"{dataset_name:<25} {compound:<8} {lod_str:>12} {loq_str:>12} {n_blank:>8}\")\n",
    "        \n",
    "        lod_table.append({\n",
    "            \"Dataset\": dataset_name,\n",
    "            \"Compound\": compound,\n",
    "            \"LOD (μg/L)\": LOD,\n",
    "            \"LOQ (μg/L)\": LOQ,\n",
    "            \"Blank Samples (n)\": n_blank,\n",
    "            \"Total Samples (n)\": n_total\n",
    "        })\n",
    "\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Save LOD results to CSV\n",
    "lod_df = pd.DataFrame(lod_table)\n",
    "lod_df.to_csv(\"lod_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_gpu)",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
